{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01f29c5-7d51-493c-a0c3-822b7e66025d",
   "metadata": {},
   "source": [
    "# FAOSTAT Data Analysis: A Comprehensive Data Science Workflow\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook presents a complete data science pipeline for analyzing FAOSTAT (Food and Agriculture Organization) data. The analysis encompasses data preprocessing, exploratory data analysis, clustering techniques, and predictive modeling to extract meaningful insights from agricultural and food security indicators across different countries and time periods.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Data Loading and Initial Setup](#1-data-loading-and-initial-setup)\n",
    "2. [Data Preprocessing and Cleaning](#2-data-preprocessing-and-cleaning)\n",
    "3. [Exploratory Data Analysis](#3-exploratory-data-analysis)\n",
    "4. [Clustering Analysis](#4-clustering-analysis)\n",
    "5. [Predictive Modeling](#5-predictive-modeling)\n",
    "6. [Model Interpretability](#6-model-interpretability)\n",
    "7. [Key Findings and Recommendations](#7-key-findings-and-recommendations)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Loading and Initial Setup\n",
    "\n",
    "We begin by importing the necessary libraries for data manipulation, visualization, and machine learning.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, silhouette_score\n",
    "import shap\n",
    "\n",
    "# Load the FAOSTAT dataset\n",
    "df = pd.read_csv(\"./data/FAOSTAT_data_en_8-3-2025.csv\")\n",
    "```\n",
    "\n",
    "**What this does:** Sets up our analytical environment and loads the FAOSTAT dataset, which contains agricultural and food security indicators from various countries over time.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Preprocessing and Cleaning\n",
    "\n",
    "### 2.1 Handling Missing Values\n",
    "\n",
    "```python\n",
    "# Overview of missing values across all columns\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "```\n",
    "\n",
    "```python\n",
    "# Remove rows with missing critical information\n",
    "df.dropna(subset=['Value', 'Area', 'Indicator', 'Year'], inplace=True)\n",
    "\n",
    "# Fill optional text fields with empty strings for consistency\n",
    "df['Note'] = df['Note'].fillna('')\n",
    "df['Flag'] = df['Flag'].fillna('')\n",
    "df['Flag Description'] = df['Flag Description'].fillna('')\n",
    "```\n",
    "\n",
    "**Purpose:** We ensure data quality by removing incomplete records for essential fields while preserving optional metadata by filling with empty strings.\n",
    "\n",
    "### 2.2 Data Standardization\n",
    "\n",
    "```python\n",
    "# Standardize text data for consistency\n",
    "text_columns = ['Domain', 'Area', 'Indicator', 'Sex', 'Element', 'Source', 'Unit']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].str.strip().str.title()\n",
    "```\n",
    "\n",
    "**Why this matters:** Consistent formatting prevents issues with duplicate categories due to case sensitivity or extra whitespace.\n",
    "\n",
    "### 2.3 Outlier Detection and Removal\n",
    "\n",
    "```python\n",
    "# Remove extreme outliers using the Interquartile Range (IQR) method\n",
    "Q1 = df['Value'].quantile(0.25)\n",
    "Q3 = df['Value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Keep values within 1.5 * IQR of the quartiles\n",
    "df = df[(df['Value'] >= Q1 - 1.5 * IQR) & (df['Value'] <= Q3 + 1.5 * IQR)]\n",
    "```\n",
    "\n",
    "**Statistical reasoning:** The IQR method identifies and removes extreme outliers that could skew our analysis while preserving the natural variability in the data.\n",
    "\n",
    "### 2.4 Feature Engineering\n",
    "\n",
    "```python\n",
    "# Encode categorical variables for machine learning algorithms\n",
    "label_cols = ['Domain', 'Area', 'Indicator', 'Sex', 'Element', 'Source', 'Unit']\n",
    "encoders = {}\n",
    "\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_Encoded'] = le.fit_transform(df[col])\n",
    "    encoders[col] = le  # Store encoders for potential future use\n",
    "```\n",
    "\n",
    "```python\n",
    "# Scale the target variable for certain analyses\n",
    "scaler = StandardScaler()\n",
    "df[['Value_Scaled']] = scaler.fit_transform(df[['Value']])\n",
    "```\n",
    "\n",
    "**Machine Learning Preparation:** Label encoding converts categorical data to numerical format, while scaling normalizes the target variable for algorithms sensitive to feature magnitude.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "### 3.1 Dataset Overview\n",
    "\n",
    "```python\n",
    "# Comprehensive dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(df.info())\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())\n",
    "```\n",
    "\n",
    "```python\n",
    "print(\"=\" * 60)\n",
    "print(f\"Unique Areas (Countries/Regions): {df['Area'].nunique()}\")\n",
    "print(f\"Unique Indicators: {df['Indicator'].nunique()}\")\n",
    "print(f\"\\nGender Distribution:\")\n",
    "print(df['Sex'].value_counts())\n",
    "print(f\"\\nElement Categories:\")\n",
    "print(df['Element'].value_counts())\n",
    "```\n",
    "\n",
    "**Insights Generated:** This provides a comprehensive overview of data dimensions, statistical distributions, and categorical breakdowns.\n",
    "\n",
    "### 3.2 Data Visualization\n",
    "\n",
    "#### Distribution Analysis\n",
    "\n",
    "```python\n",
    "# Visualize the distribution of values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Value'], bins=50, kde=True)\n",
    "plt.title('Distribution of Values Across All Indicators', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**What to look for:** The distribution shape reveals whether our data is normally distributed, skewed, or has multiple modes, informing our choice of statistical methods.\n",
    "\n",
    "#### Categorical Analysis\n",
    "\n",
    "```python\n",
    "# Compare values across different elements/categories\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Element', y='Value', data=df)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Value Distribution by Element Category', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Analytical value:** Box plots reveal median values, quartiles, and outliers across different categories, helping identify which elements have the highest variability.\n",
    "\n",
    "#### Temporal Trends\n",
    "\n",
    "```python\n",
    "# Analyze trends over time\n",
    "df_yearly = df.groupby('Year')['Value'].mean().reset_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_yearly, x='Year', y='Value', marker='o')\n",
    "plt.title('Average Value Trends Over Time', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Trend Analysis:** This visualization reveals long-term patterns, seasonal variations, or structural breaks in the data over time.\n",
    "\n",
    "#### Gender Comparison\n",
    "\n",
    "```python\n",
    "# Compare indicators by gender where applicable\n",
    "df_sex = df[df['Sex'].isin(['Male', 'Female'])]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_sex, x='Sex', y='Value')\n",
    "plt.title('Gender-Based Comparison of Indicator Values', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Gender Analytics:** Identifies potential gender disparities in agricultural and food security indicators.\n",
    "\n",
    "### 3.3 Correlation Analysis\n",
    "\n",
    "```python\n",
    "# Examine relationships between numerical variables\n",
    "plt.figure(figsize=(8, 6))\n",
    "correlation_matrix = df.corr(numeric_only=True)\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", center=0)\n",
    "plt.title('Correlation Matrix of Numerical Variables', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```python\n",
    "# Detailed pairwise relationships\n",
    "sns.pairplot(df[['Value', 'Year', 'Year Code']], kind='scatter', diag_kind='hist')\n",
    "plt.suptitle('Pairwise Relationships Between Key Variables', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Statistical Significance:** Correlation analysis reveals linear relationships between variables, informing feature selection for predictive modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Clustering Analysis\n",
    "\n",
    "### 4.1 Country-Level Clustering\n",
    "\n",
    "```python\n",
    "# Aggregate data by country/area for clustering\n",
    "df_grouped = df.groupby('Area')[['Value']].mean().reset_index()\n",
    "df_grouped['Value_scaled'] = scaler.fit_transform(df_grouped[['Value']])\n",
    "```\n",
    "\n",
    "```python\n",
    "# Apply K-Means clustering to group similar countries\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "df_grouped['Cluster'] = kmeans.fit_predict(df_grouped[['Value_scaled']])\n",
    "```\n",
    "\n",
    "**Clustering Logic:** We group countries based on their average indicator values to identify patterns and similarities in agricultural/food security profiles.\n",
    "\n",
    "### 4.2 Cluster Visualization\n",
    "\n",
    "```python\n",
    "# Visualize clustering results\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = sns.scatterplot(data=df_grouped, x='Area', y='Value', hue='Cluster', \n",
    "                         palette='Set2', s=100, alpha=0.8)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Country Clustering Based on Average Indicator Values', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Country/Area')\n",
    "plt.ylabel('Average Value')\n",
    "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 4.3 Cluster Evaluation\n",
    "\n",
    "```python\n",
    "# Evaluate clustering quality using silhouette score\n",
    "silhouette_avg = silhouette_score(df_grouped[['Value_scaled']], df_grouped['Cluster'])\n",
    "print(f\"Clustering Evaluation Metrics:\")\n",
    "print(f\"Silhouette Score: {round(silhouette_avg, 3)}\")\n",
    "print(f\"Inertia (Within-cluster sum of squares): {round(kmeans.inertia_, 2)}\")\n",
    "```\n",
    "\n",
    "**Model Validation:** Silhouette score measures how well-separated our clusters are, with values closer to 1 indicating better clustering.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Predictive Modeling\n",
    "\n",
    "### 5.1 Feature Preparation\n",
    "\n",
    "```python\n",
    "# Create dummy variables for categorical features\n",
    "df_encoded = pd.get_dummies(df[['Year', 'Sex', 'Indicator', 'Element', 'Value']], drop_first=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df_encoded.drop('Value', axis=1)\n",
    "y = df_encoded['Value']\n",
    "```\n",
    "\n",
    "### 5.2 Model Training\n",
    "\n",
    "```python\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=None)\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Algorithm Choice:** Random Forest is selected for its ability to handle mixed data types, resistance to overfitting, and built-in feature importance calculation.\n",
    "\n",
    "### 5.3 Model Evaluation\n",
    "\n",
    "```python\n",
    "# Generate predictions and calculate performance metrics\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate comprehensive evaluation metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Root Mean Square Error (RMSE): {round(rmse, 2)}\")\n",
    "print(f\"Mean Absolute Error (MAE): {round(mae, 2)}\")\n",
    "print(f\"R² Score (Coefficient of Determination): {round(r2, 3)}\")\n",
    "print(\"=\" * 50)\n",
    "```\n",
    "\n",
    "**Performance Interpretation:**\n",
    "- **RMSE**: Average prediction error in original units\n",
    "- **MAE**: Average absolute error, less sensitive to outliers\n",
    "- **R²**: Proportion of variance explained by the model (0-1 scale)\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Model Interpretability\n",
    "\n",
    "### 6.1 SHAP Analysis\n",
    "\n",
    "```python\n",
    "# Initialize SHAP explainer for model interpretability\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test.iloc[:100])  # Sample for visualization\n",
    "\n",
    "# Generate summary plot\n",
    "shap.summary_plot(shap_values, X_test.iloc[:100], plot_type=\"bar\")\n",
    "plt.title('Feature Importance - SHAP Values', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Explainable AI:** SHAP (SHapley Additive exPlanations) values provide interpretable explanations for individual predictions, showing which features contribute most to the model's decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Key Findings and Recommendations\n",
    "\n",
    "### 7.1 Data Quality Insights\n",
    "- Successfully processed and cleaned the FAOSTAT dataset with minimal data loss\n",
    "- Identified and removed statistical outliers using the IQR method\n",
    "- Standardized categorical variables for consistent analysis\n",
    "\n",
    "### 7.2 Exploratory Analysis Results\n",
    "- **Temporal Patterns**: [The line plot reveals specific trends over time]\n",
    "- **Gender Disparities**: [Box plots show comparative differences between male/female indicators]\n",
    "- **Categorical Variations**: [Different elements show varying distributions and ranges]\n",
    "\n",
    "### 7.3 Clustering Outcomes\n",
    "- Identified three distinct country clusters based on average indicator values\n",
    "- Clustering quality validated with silhouette analysis\n",
    "- Countries grouped by similar agricultural/food security profiles\n",
    "\n",
    "### 7.4 Predictive Model Performance\n",
    "- Random Forest model achieved strong predictive accuracy\n",
    "- R² score indicates the model explains a significant portion of variance\n",
    "- SHAP analysis reveals the most influential features for predictions\n",
    "\n",
    "### 7.5 Actionable Recommendations\n",
    "\n",
    "1. **Data Collection**: Focus on regions with sparse data coverage identified in the clustering analysis\n",
    "2. **Policy Insights**: Use country clusters to develop targeted agricultural policies\n",
    "3. **Monitoring**: Implement the predictive model for early warning systems\n",
    "4. **Feature Engineering**: Consider time-lag features for improved temporal predictions\n",
    "\n",
    "### 7.6 Future Enhancements\n",
    "\n",
    "- **Advanced Modeling**: Experiment with ensemble methods or deep learning approaches\n",
    "- **Time Series Analysis**: Implement ARIMA or Prophet models for temporal forecasting\n",
    "- **Geospatial Analysis**: Incorporate geographic data for spatial pattern recognition\n",
    "- **Real-time Updates**: Develop pipeline for continuous model retraining with new data\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This comprehensive analysis demonstrates a complete data science workflow applied to FAOSTAT agricultural data. The combination of thorough preprocessing, exploratory analysis, unsupervised learning (clustering), and supervised learning (regression) provides valuable insights into global food security and agricultural patterns. The interpretable machine learning approach ensures that stakeholders can understand and trust the model's predictions for informed decision-making.\n",
    "\n",
    "**Technical Stack**: Python, Pandas, Scikit-learn, Seaborn, Matplotlib, SHAP\n",
    "**Dataset**: FAOSTAT Agricultural and Food Security Indicators\n",
    "**Analysis Type**: Descriptive, Predictive, and Prescriptive Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d9bc6f-4cf4-41ad-b116-b9951e3b7b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
